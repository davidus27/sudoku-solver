{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH=\"./trained_model/cp.ckpt\"\n",
    "EPOCHS_AMOUNT=5\n",
    "CLASSES_AMOUNT=10\n",
    "BATCH_SIZE=200\n",
    "\n",
    "IMG_DIMENSIONS=28\n",
    "NUMBER_THREAD=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(10):\n",
    "    for d in os.listdir(\"imgs/digits/{}\".format(i)):\n",
    "        t_img = cv.imread(\"imgs/digits/{}\".format(i)+\"/\"+d)\n",
    "        t_img = cv.cvtColor(t_img,cv.COLOR_BGR2GRAY)\n",
    "        X.append(t_img)\n",
    "        y.append(i)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIMENSIONS, IMG_DIMENSIONS, 1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                activation='relu',\n",
    "                input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(CLASSES_AMOUNT, activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(image_train, labels_train) , (image_test, labels_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state= 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = image_train.reshape(image_train.shape[0],\n",
    "                                    IMG_DIMENSIONS,\n",
    "                                    IMG_DIMENSIONS,\n",
    "                                    1)\n",
    "image_train = image_train.astype(np.float32) / 255\n",
    "\n",
    "image_test = image_test.reshape(image_test.shape[0],\n",
    "                                    IMG_DIMENSIONS,\n",
    "                                    IMG_DIMENSIONS,\n",
    "                                    1)\n",
    "image_test = image_test.astype(np.float32) / 255\n",
    "\n",
    "labels_train = utils.to_categorical(labels_train, \n",
    "                                        num_classes=CLASSES_AMOUNT)\n",
    "labels_test = utils.to_categorical(labels_test, \n",
    "                                        num_classes=CLASSES_AMOUNT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.9169\n",
      "Epoch 00001: saving model to ./trained_model\\cp.ckpt\n",
      "300/300 [==============================] - 64s 212ms/step - loss: 0.2758 - accuracy: 0.9169 - val_loss: 0.0580 - val_accuracy: 0.9815\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9717\n",
      "Epoch 00002: saving model to ./trained_model\\cp.ckpt\n",
      "300/300 [==============================] - 66s 221ms/step - loss: 0.0958 - accuracy: 0.9717 - val_loss: 0.0427 - val_accuracy: 0.9861\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9778\n",
      "Epoch 00003: saving model to ./trained_model\\cp.ckpt\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.0730 - accuracy: 0.9778 - val_loss: 0.0372 - val_accuracy: 0.9883\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9817\n",
      "Epoch 00004: saving model to ./trained_model\\cp.ckpt\n",
      "300/300 [==============================] - 66s 221ms/step - loss: 0.0583 - accuracy: 0.9817 - val_loss: 0.0297 - val_accuracy: 0.9894\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9849\n",
      "Epoch 00005: saving model to ./trained_model\\cp.ckpt\n",
      "300/300 [==============================] - 64s 213ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 0.0323 - val_accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e742e5d580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = os.path.dirname(CHECKPOINT_PATH)\n",
    "\n",
    "cp_callback = ModelCheckpoint(filepath=CHECKPOINT_PATH,\n",
    "                                save_weights_only=True,\n",
    "                                verbose=1)\n",
    "model.fit(image_train,\n",
    "            labels_train,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS_AMOUNT,\n",
    "            verbose=1,\n",
    "            validation_data=(image_test, labels_test),\n",
    "            callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - loss: 0.0323 - accuracy: 0.9890 - 3s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9890000224113464"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(image_test,  labels_test, verbose=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('imgs/')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(\u001b[38;5;241m1\u001b[39m, IMG_DIMENSIONS, IMG_DIMENSIONS, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39margmax()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b28e3fb1f5df41a76302ba89784f5eede344a036d768b47b82471c93d29db6fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
